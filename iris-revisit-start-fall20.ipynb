{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A \"Hello World\" Example of Machine Learning - Revisit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Iris dataset from scikit-learn. \n",
    "\n",
    "The first column represents Sepal length, the second column represents Sepal width,  the third column represents the petal length, and the fourth column the petal width of the flower samples. The classes (type of species) are already converted to integer labels where 0=Iris-Setosa, 1=Iris-Versicolor, 2=Iris-Virginica.\n",
    "\n",
    "Here, we are using only two features: the third and fourth columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "#iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:, [0, 3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Class labels: [0 1 2]\n"
    }
   ],
   "source": [
    "print('Class labels:', np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn algorithms support multi-class classification via the One-Versus-Rest(OvR) method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into 70% training and 30% test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Labels counts in y: [50 50 50]\nLabels counts in y_train: [35 35 35]\nLabels counts in y_test: [15 15 15]\n"
    }
   ],
   "source": [
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Labels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler() #center the distribution around zero (mean), with a standard deviation of 1.\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Perceptron(eta0=0.1, max_iter=100, random_state=42)"
     },
     "metadata": {},
     "execution_count": 993
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "ppn = Perceptron(max_iter=100, eta0=0.1, random_state=42)\n",
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model with the hold-out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Misclassified samples: 10\n"
    }
   ],
   "source": [
    "y_pred = ppn.predict(X_test_std)\n",
    "print('Misclassified samples: ' + str((y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.7777777777777778\n"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2, 2, 2])"
     },
     "metadata": {},
     "execution_count": 996
    }
   ],
   "source": [
    "X_new = [[1.1, 0.2],[0.4, 1.9], [1.4, 0.2]]\n",
    "y_new = ppn.predict(X_new)\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.88888889, 0.76923077, 0.53846154, 0.80769231])"
     },
     "metadata": {},
     "execution_count": 997
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(ppn, X_train_std, y_train, cv=4, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-features: sccuracy score: array([0.88888889, 0.48148148, 0.7037037 , 0.95833333])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Use all four features to train the model and use cross validaton to check if the results better? Briefly explain why. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Class labels: [0 1 2]\n"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0,1,2,3]]\n",
    "y = iris.target\n",
    "print('Class labels:', np.unique(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Labels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler() #center the distribution around zero (mean), with a standard deviation of 1.\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Perceptron(eta0=0.1, max_iter=100, random_state=42)"
     },
     "metadata": {},
     "execution_count": 1002
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "ppn = Perceptron(max_iter=100, eta0=0.1, random_state=42)\n",
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Misclassified samples: 3\n"
    }
   ],
   "source": [
    "y_pred = ppn.predict(X_test_std)\n",
    "print('Misclassified samples: ' + str((y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.9333333333333333\n"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1, 1, 1])"
     },
     "metadata": {},
     "execution_count": 1005
    }
   ],
   "source": [
    "X_new = [[5.1,3.5,1.4,0.2],[4.9,3.0,1.4,0.2], [4.7,3.2,1.3,0.2]]\n",
    "y_new = ppn.predict(X_new)\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.92592593, 0.88461538, 0.84615385, 0.88461538])"
     },
     "metadata": {},
     "execution_count": 1006
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(ppn, X_train_std, y_train, cv=4, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy for 2 features = 0.7777777777777778\n",
    "### cross_value_score for 2 features =array([0.88888889, 0.76923077, 0.53846154, 0.80769231])\n",
    "\n",
    "### Accuracy for 4 features =  0.9333333333333333\n",
    "### cross_value_score for 4 features = array([0.92592593, 0.88888889, 0.81481481, 0.91666667])\n",
    "\n",
    "#### therefore accuracy is high with 4-features than 2-features and also cross_value_score also increases for 4-features, \n",
    "output is better with four features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Try with the scikit-learn stochastic gradient descent model instead of perceptron. Use all four features. Evaluate with cross-validation how does the model perform in terms of accuracy using both two features and four features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "#iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:, [1,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Class labels: [0 1 2]\n"
    }
   ],
   "source": [
    "print('Class labels:', np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Labels counts in y: [50 50 50]\nLabels counts in y_train: [35 35 35]\nLabels counts in y_test: [15 15 15]\n"
    }
   ],
   "source": [
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Labels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler() #center the distribution around zero (mean), with a standard deviation of 1.\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "SGDClassifier(random_state=42)"
     },
     "metadata": {},
     "execution_count": 1014
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(random_state=42)\n",
    "sgd.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Misclassified samples: 1\n"
    }
   ],
   "source": [
    "y_pred = sgd.predict(X_test_std)\n",
    "print('Misclassified samples: ' + str((y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.9777777777777777\n"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1, 1, 1])"
     },
     "metadata": {},
     "execution_count": 1017
    }
   ],
   "source": [
    "X_new = [[5.1,3.5,1.4,0.2],[4.9,3.0,1.4,0.2], [4.7,3.2,1.3,0.2]]\n",
    "y_new = ppn.predict(X_new)\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.88888889, 0.84615385, 0.80769231, 0.80769231])"
     },
     "metadata": {},
     "execution_count": 1018
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(ppn, X_train_std, y_train, cv=4, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 4 features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "#iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:, [0,1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Class labels: [0 1 2]\n"
    }
   ],
   "source": [
    "print('Class labels:', np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Labels counts in y: [50 50 50]\nLabels counts in y_train: [35 35 35]\nLabels counts in y_test: [15 15 15]\n"
    }
   ],
   "source": [
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Labels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler() #center the distribution around zero (mean), with a standard deviation of 1.\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "SGDClassifier(random_state=42)"
     },
     "metadata": {},
     "execution_count": 1026
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "sgd = SGDClassifier(random_state=42)\n",
    "sgd.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Misclassified samples: 5\n"
    }
   ],
   "source": [
    "y_pred = sgd.predict(X_test_std)\n",
    "print('Misclassified samples: ' + str((y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.8888888888888888\n"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1, 1, 1])"
     },
     "metadata": {},
     "execution_count": 1029
    }
   ],
   "source": [
    "X_new = [[5.1,3.5,1.4,0.2],[4.9,3.0,1.4,0.2], [4.7,3.2,1.3,0.2]]\n",
    "y_new = ppn.predict(X_new)\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.92592593, 0.88461538, 0.84615385, 0.88461538])"
     },
     "metadata": {},
     "execution_count": 1030
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(ppn, X_train_std, y_train, cv=4, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy for 2 features =:0.9777777777777777\n",
    "array for two features([0.88888889, 0.84615385, 0.80769231, 0.80769231])\n",
    "\n",
    "Accuracy for four features: 0.8888888888888888\n",
    "array for four features([0.92592593, 0.88461538, 0.84615385, 0.88461538])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python_defaultSpec_1600806351389"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}